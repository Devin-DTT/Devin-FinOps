From 73860e78da5c95cfc69b141b35cd27d0f879d7b4 Mon Sep 17 00:00:00 2001
From: Devin AI <158243242+devin-ai-integration[bot]@users.noreply.github.com>
Date: Tue, 21 Oct 2025 10:24:44 +0000
Subject: [PATCH] Add FastAPI Mock Usage Data API with test client

- Implement FastAPI application with Pydantic models for usage logs
- Create /api/v1/usage_logs endpoint with pagination support
- Create /api/v1/cost_settings endpoint for cost configuration
- Generate 1,000 mock usage log records with data variability
- Add test client script to verify API functionality
- All required fields included: session_id, user_id, organization_id, project_id, pull_request_id, timestamp, acu_consumed, business_unit, task_type, is_out_of_hours, is_merged, session_outcome
- API runs on port 8000 as specified
- Test client validates pagination and data schema successfully

Co-Authored-By: gtorreshuamantica@deloitte.es <gtorreshuamantica@deloitte.es>
---
 .gitignore         |  29 +++++++++
 api_test_client.py | 151 +++++++++++++++++++++++++++++++++++++++++++++
 main.py            |  74 ++++++++++++++++++++++
 mock_data.py       |  65 +++++++++++++++++++
 models.py          |  78 +++++++++++++++++++++++
 requirements.txt   |   5 ++
 6 files changed, 402 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 api_test_client.py
 create mode 100644 main.py
 create mode 100644 mock_data.py
 create mode 100644 models.py
 create mode 100644 requirements.txt

diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..268f692
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,29 @@
+__pycache__/
+*.py[cod]
+*$py.class
+*.so
+.Python
+build/
+develop-eggs/
+dist/
+downloads/
+eggs/
+.eggs/
+lib/
+lib64/
+parts/
+sdist/
+var/
+wheels/
+*.egg-info/
+.installed.cfg
+*.egg
+venv/
+env/
+ENV/
+.venv
+.DS_Store
+*.log
+.pytest_cache/
+.coverage
+htmlcov/
diff --git a/api_test_client.py b/api_test_client.py
new file mode 100644
index 0000000..77b8562
--- /dev/null
+++ b/api_test_client.py
@@ -0,0 +1,151 @@
+import requests
+import json
+from typing import Optional
+
+
+class FinOpsAPIClient:
+    def __init__(self, base_url: str = "http://localhost:8000"):
+        self.base_url = base_url
+    
+    def test_usage_logs(self, page: int = 1, page_size: int = 50) -> dict:
+        url = f"{self.base_url}/api/v1/usage_logs"
+        params = {"page": page, "page_size": page_size}
+        
+        try:
+            response = requests.get(url, params=params)
+            response.raise_for_status()
+            return response.json()
+        except requests.exceptions.RequestException as e:
+            print(f"Error fetching usage logs: {e}")
+            return None
+    
+    def test_cost_settings(self) -> dict:
+        url = f"{self.base_url}/api/v1/cost_settings"
+        
+        try:
+            response = requests.get(url)
+            response.raise_for_status()
+            return response.json()
+        except requests.exceptions.RequestException as e:
+            print(f"Error fetching cost settings: {e}")
+            return None
+    
+    def validate_usage_log_schema(self, log: dict) -> bool:
+        required_fields = [
+            "session_id", "user_id", "organization_id", "project_id",
+            "timestamp", "acu_consumed", "business_unit", "task_type",
+            "is_out_of_hours", "is_merged", "session_outcome"
+        ]
+        
+        for field in required_fields:
+            if field not in log:
+                print(f"Missing required field: {field}")
+                return False
+        
+        if not isinstance(log["acu_consumed"], (int, float)):
+            print(f"Invalid type for acu_consumed: {type(log['acu_consumed'])}")
+            return False
+        
+        if not isinstance(log["is_out_of_hours"], bool):
+            print(f"Invalid type for is_out_of_hours: {type(log['is_out_of_hours'])}")
+            return False
+        
+        if not isinstance(log["is_merged"], bool):
+            print(f"Invalid type for is_merged: {type(log['is_merged'])}")
+            return False
+        
+        return True
+    
+    def run_tests(self):
+        print("=" * 70)
+        print("FinOps Mock Usage Data API - Test Client")
+        print("=" * 70)
+        print()
+        
+        print("Test 1: Fetching usage logs (page 1, page_size=10)")
+        print("-" * 70)
+        response = self.test_usage_logs(page=1, page_size=10)
+        if response:
+            print(f"✓ Response received")
+            print(f"  Total records: {response['total']}")
+            print(f"  Page: {response['page']}")
+            print(f"  Page size: {response['page_size']}")
+            print(f"  Total pages: {response['total_pages']}")
+            print(f"  Records in this page: {len(response['data'])}")
+            print()
+            
+            if response['data']:
+                print("Test 2: Validating data schema for first record")
+                print("-" * 70)
+                first_log = response['data'][0]
+                if self.validate_usage_log_schema(first_log):
+                    print("✓ Schema validation passed")
+                    print()
+                    print("Sample record:")
+                    print(json.dumps(first_log, indent=2))
+                else:
+                    print("✗ Schema validation failed")
+                print()
+        else:
+            print("✗ Failed to fetch usage logs")
+            print()
+        
+        print("Test 3: Testing pagination (page 2)")
+        print("-" * 70)
+        response_page2 = self.test_usage_logs(page=2, page_size=10)
+        if response_page2:
+            print(f"✓ Page 2 fetched successfully")
+            print(f"  Records in page 2: {len(response_page2['data'])}")
+            print()
+        else:
+            print("✗ Failed to fetch page 2")
+            print()
+        
+        print("Test 4: Testing large page size")
+        print("-" * 70)
+        response_large = self.test_usage_logs(page=1, page_size=100)
+        if response_large:
+            print(f"✓ Large page fetched successfully")
+            print(f"  Records fetched: {len(response_large['data'])}")
+            print()
+        else:
+            print("✗ Failed to fetch large page")
+            print()
+        
+        print("Test 5: Fetching cost settings")
+        print("-" * 70)
+        cost_settings = self.test_cost_settings()
+        if cost_settings:
+            print("✓ Cost settings retrieved successfully")
+            print(json.dumps(cost_settings, indent=2))
+            print()
+        else:
+            print("✗ Failed to fetch cost settings")
+            print()
+        
+        print("Test 6: Verifying data variability")
+        print("-" * 70)
+        if response:
+            business_units = set()
+            task_types = set()
+            outcomes = set()
+            
+            for log in response['data']:
+                business_units.add(log['business_unit'])
+                task_types.add(log['task_type'])
+                outcomes.add(log['session_outcome'])
+            
+            print(f"✓ Data variability confirmed")
+            print(f"  Unique business units: {len(business_units)} - {business_units}")
+            print(f"  Unique task types: {len(task_types)} - {task_types}")
+            print(f"  Unique outcomes: {len(outcomes)} - {outcomes}")
+            print()
+        
+        print("=" * 70)
+        print("All tests completed!")
+        print("=" * 70)
+
+
+if __name__ == "__main__":
+    client = FinOpsAPIClient()
+    client.run_tests()
diff --git a/main.py b/main.py
new file mode 100644
index 0000000..0f919a1
--- /dev/null
+++ b/main.py
@@ -0,0 +1,74 @@
+from fastapi import FastAPI, Query
+from fastapi.responses import JSONResponse
+from models import UsageLogsResponse, CostSettings
+from mock_data import MOCK_LOGS
+import math
+
+app = FastAPI(
+    title="FinOps Mock Usage Data API",
+    description="Mock API for serving usage data logs for the FinOps Automation Project",
+    version="1.0.0"
+)
+
+
+@app.get("/")
+def root():
+    return {
+        "message": "FinOps Mock Usage Data API",
+        "version": "1.0.0",
+        "endpoints": {
+            "usage_logs": "/api/v1/usage_logs",
+            "cost_settings": "/api/v1/cost_settings"
+        }
+    }
+
+
+@app.get("/api/v1/usage_logs", response_model=UsageLogsResponse)
+def get_usage_logs(
+    page: int = Query(1, ge=1, description="Page number"),
+    page_size: int = Query(50, ge=1, le=500, description="Number of items per page")
+):
+    total = len(MOCK_LOGS)
+    total_pages = math.ceil(total / page_size)
+    
+    if page > total_pages and total > 0:
+        return JSONResponse(
+            status_code=404,
+            content={
+                "detail": f"Page {page} not found. Total pages: {total_pages}"
+            }
+        )
+    
+    start_idx = (page - 1) * page_size
+    end_idx = start_idx + page_size
+    
+    paginated_logs = MOCK_LOGS[start_idx:end_idx]
+    
+    return UsageLogsResponse(
+        data=paginated_logs,
+        total=total,
+        page=page,
+        page_size=page_size,
+        total_pages=total_pages
+    )
+
+
+@app.get("/api/v1/cost_settings", response_model=CostSettings)
+def get_cost_settings():
+    return CostSettings(
+        acu_base_cost=0.10,
+        out_of_hours_multiplier=1.5,
+        business_unit_rates={
+            "Finance": 1.2,
+            "Engineering": 1.0,
+            "Operations": 0.9,
+            "Marketing": 1.1,
+            "Sales": 1.15,
+            "HR": 0.95
+        }
+    )
+
+
+if __name__ == "__main__":
+    import uvicorn
+    uvicorn.run(app, host="0.0.0.0", port=8000)
diff --git a/mock_data.py b/mock_data.py
new file mode 100644
index 0000000..8437283
--- /dev/null
+++ b/mock_data.py
@@ -0,0 +1,65 @@
+import random
+from datetime import datetime, timedelta
+from models import UsageLog, SessionOutcome, TaskType
+
+
+def generate_mock_logs(count: int = 1000) -> list[UsageLog]:
+    logs = []
+    
+    business_units = ["Finance", "Engineering", "Operations", "Marketing", "Sales", "HR"]
+    organizations = [f"org_{i:03d}" for i in range(1, 11)]
+    projects = [f"proj_{i:03d}" for i in range(1, 51)]
+    users = [f"user_{i:04d}" for i in range(1, 101)]
+    
+    base_time = datetime(2025, 1, 1, 0, 0, 0)
+    
+    for i in range(count):
+        session_id = f"sess_{i:06d}"
+        user_id = random.choice(users)
+        organization_id = random.choice(organizations)
+        project_id = random.choice(projects)
+        
+        has_pr = random.random() > 0.3
+        pull_request_id = f"pr_{random.randint(1, 9999)}" if has_pr else None
+        
+        timestamp = base_time + timedelta(
+            days=random.randint(0, 290),
+            hours=random.randint(0, 23),
+            minutes=random.randint(0, 59),
+            seconds=random.randint(0, 59)
+        )
+        
+        acu_consumed = round(random.uniform(10.0, 500.0), 2)
+        
+        business_unit = random.choice(business_units)
+        task_type = random.choice(list(TaskType))
+        
+        hour = timestamp.hour
+        is_out_of_hours = hour < 8 or hour >= 18 or timestamp.weekday() >= 5
+        
+        outcome = random.choice(list(SessionOutcome))
+        is_merged = outcome == SessionOutcome.SUCCESS and has_pr and random.random() > 0.2
+        
+        log = UsageLog(
+            session_id=session_id,
+            user_id=user_id,
+            organization_id=organization_id,
+            project_id=project_id,
+            pull_request_id=pull_request_id,
+            timestamp=timestamp,
+            acu_consumed=acu_consumed,
+            business_unit=business_unit,
+            task_type=task_type,
+            is_out_of_hours=is_out_of_hours,
+            is_merged=is_merged,
+            session_outcome=outcome
+        )
+        
+        logs.append(log)
+    
+    logs.sort(key=lambda x: x.timestamp, reverse=True)
+    
+    return logs
+
+
+MOCK_LOGS = generate_mock_logs(1000)
diff --git a/models.py b/models.py
new file mode 100644
index 0000000..26a4010
--- /dev/null
+++ b/models.py
@@ -0,0 +1,78 @@
+from pydantic import BaseModel, Field
+from typing import Optional
+from datetime import datetime
+from enum import Enum
+
+
+class SessionOutcome(str, Enum):
+    SUCCESS = "Success"
+    FAILURE = "Failure"
+    IDLE = "Idle"
+
+
+class TaskType(str, Enum):
+    BUGFIX = "BugFix"
+    REFACTOR = "Refactor"
+    FEATURE = "Feature"
+    TESTING = "Testing"
+    DOCUMENTATION = "Documentation"
+
+
+class UsageLog(BaseModel):
+    session_id: str = Field(..., description="Unique session identifier")
+    user_id: str = Field(..., description="User identifier")
+    organization_id: str = Field(..., description="Organization identifier")
+    project_id: str = Field(..., description="Project identifier")
+    pull_request_id: Optional[str] = Field(None, description="Pull request identifier if applicable")
+    timestamp: datetime = Field(..., description="Timestamp of the log entry")
+    acu_consumed: float = Field(..., description="Agent Compute Units consumed", ge=0)
+    business_unit: str = Field(..., description="Business unit for tribal cost allocation")
+    task_type: TaskType = Field(..., description="Type of task being performed")
+    is_out_of_hours: bool = Field(..., description="Whether the work was done outside business hours")
+    is_merged: bool = Field(..., description="Whether the PR was merged successfully")
+    session_outcome: SessionOutcome = Field(..., description="Outcome of the session")
+
+    class Config:
+        json_schema_extra = {
+            "example": {
+                "session_id": "sess_abc123",
+                "user_id": "user_001",
+                "organization_id": "org_deloitte",
+                "project_id": "proj_finops",
+                "pull_request_id": "pr_456",
+                "timestamp": "2025-10-21T10:00:00Z",
+                "acu_consumed": 125.5,
+                "business_unit": "Finance",
+                "task_type": "BugFix",
+                "is_out_of_hours": False,
+                "is_merged": True,
+                "session_outcome": "Success"
+            }
+        }
+
+
+class UsageLogsResponse(BaseModel):
+    data: list[UsageLog]
+    total: int
+    page: int
+    page_size: int
+    total_pages: int
+
+
+class CostSettings(BaseModel):
+    acu_base_cost: float = Field(..., description="Base cost per ACU")
+    out_of_hours_multiplier: float = Field(..., description="Cost multiplier for out-of-hours work")
+    business_unit_rates: dict[str, float] = Field(..., description="Cost rates by business unit")
+    
+    class Config:
+        json_schema_extra = {
+            "example": {
+                "acu_base_cost": 0.10,
+                "out_of_hours_multiplier": 1.5,
+                "business_unit_rates": {
+                    "Finance": 1.2,
+                    "Engineering": 1.0,
+                    "Operations": 0.9
+                }
+            }
+        }
diff --git a/requirements.txt b/requirements.txt
new file mode 100644
index 0000000..25e4ed9
--- /dev/null
+++ b/requirements.txt
@@ -0,0 +1,5 @@
+fastapi==0.104.1
+uvicorn[standard]==0.24.0
+pydantic==2.5.0
+python-dateutil==2.8.2
+requests==2.31.0
-- 
2.34.1

